version: '3.8'

services:
  lm-evaluation-harness:
    image: lm-evaluation-harness
    container_name: gplsi_lm-evaluation-harness
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - WANDB_API_KEY=${WANDB_API_KEY}
      - MODELS_TO_EVALUATE=$MODELS_TO_EVALUATE 
      - HF_TOKEN=${HF_TOKEN}
      - WANDB_PROJECT=$WANDB_PROJECT
      - USER_ID=${USER_ID}
      - GROUP_ID=${GROUP_ID}
      - INSTRUCT_EVALUATION=${INSTRUCT_EVALUATION}
    network_mode: "host"  # Use host network (same as --network="host" in docker run)
    stdin_open: true  # Keeps the stdin open (interactive mode)
    tty: true  # Allocate a pseudo-TTY (interactive terminal)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ["all"] #["0","3","4"]  # Let the container use all GPUs

    volumes:
    - ./outputLogs/:/outputLogs
    - /home/gplsi/NAS/GPLSI/ALIA/modelos/Instruction/Intruccion_v1_salamandra_2B/evaluaciones:/app/results
    - /home/gplsi/NAS/GPLSI/ALIA/modelos/Instruction/Intruccion_v1_salamandra_2B/reports:/app/reports
    - /home/gplsi/NAS/GPLSI/ALIA/modelos/Instruction/Intruccion_v1_salamandra_2B/hf_models:/models
    #- /home/gplsi/NAS/GPLSI/HF_models/SALAMANDRA/modelos:/models
    #- /home/gplsi/NAS/GPLSI/HF_models:/models
    #- /home/gplsi/NAS/GPLSI/odesiaChallenge/models:/models
    #- /home/NAS/GPLSI/:/home/NAS/GPLSI
    #- /home/gplsi/NAS/mikel/outputLogs/:/outputLogs
    #- /home/gplsi/NAS/mikel/results/:/app/results
    #- /home/gplsi/NAS/mikel/reports/:/app/reports
    #- /home/gplsi/NAS/GPLSI/llm-train-tokenizer-custom-dataset-main/modelos:/models
