Available GPUs: 2
Instruct evaluation: False
The model name does not contain '.nemo'.
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `2`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2025-05-28:17:48:34 INFO     [__main__:440] Selected Tasks: ['belebele_spa_Latn', 'wnli_es', 'xnli_es', 'xquad_es', 'xstorycloze_es']
2025-05-28:17:48:34 INFO     [__main__:440] Selected Tasks: ['belebele_spa_Latn', 'wnli_es', 'xnli_es', 'xquad_es', 'xstorycloze_es']
2025-05-28:17:48:34 INFO     [evaluator:185] Setting random seed to 1234 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-05-28:17:48:34 INFO     [evaluator:185] Setting random seed to 1234 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-05-28:17:48:34 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt', 'trust_remote_code': True}
2025-05-28:17:48:34 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt', 'trust_remote_code': True}
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/utils/hub.py", line 470, in cached_files
[rank0]:     hf_hub_download(
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank0]:     validate_repo_id(arg_value)
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank0]:     raise HFValidationError(
[rank0]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt'. Use `repo_type` argument if needed.

[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/configuration_utils.py", line 654, in _get_config_dict
[rank0]:     resolved_config_file = cached_file(
[rank0]:                            ^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/utils/hub.py", line 312, in cached_file
[rank0]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/utils/hub.py", line 523, in cached_files
[rank0]:     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) for filename in full_filenames
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/utils/hub.py", line 140, in _get_cache_file_to_return
[rank0]:     resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir=cache_dir, revision=revision)
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank0]:     validate_repo_id(arg_value)
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank0]:     raise HFValidationError(
[rank0]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt'. Use `repo_type` argument if needed.

[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/__main__.py", line 530, in <module>
[rank0]:     cli_evaluate()
[rank0]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/__main__.py", line 449, in cli_evaluate
[rank0]:     results = evaluator.simple_evaluate(
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/utils.py", line 439, in _wrapper
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/evaluator.py", line 226, in simple_evaluate
[rank0]:     lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/api/model.py", line 151, in create_from_arg_string
[rank0]:     return cls(**args, **args2)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/models/huggingface.py", line 168, in __init__
[rank0]:     self._get_config(
[rank0]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/models/huggingface.py", line 527, in _get_config
[rank0]:     self._config = transformers.AutoConfig.from_pretrained(
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1153, in from_pretrained
[rank0]:     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank0]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/configuration_utils.py", line 595, in get_config_dict
[rank0]:     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank0]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/configuration_utils.py", line 677, in _get_config_dict
[rank0]:     raise OSError(
[rank0]: OSError: Can't load the configuration of '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt' is the correct path to a directory containing a config.json file
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/utils/hub.py", line 470, in cached_files
[rank1]:     hf_hub_download(
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank1]:     validate_repo_id(arg_value)
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank1]:     raise HFValidationError(
[rank1]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt'. Use `repo_type` argument if needed.

[rank1]: During handling of the above exception, another exception occurred:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/configuration_utils.py", line 654, in _get_config_dict
[rank1]:     resolved_config_file = cached_file(
[rank1]:                            ^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/utils/hub.py", line 312, in cached_file
[rank1]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/utils/hub.py", line 523, in cached_files
[rank1]:     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) for filename in full_filenames
[rank1]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/utils/hub.py", line 140, in _get_cache_file_to_return
[rank1]:     resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir=cache_dir, revision=revision)
[rank1]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank1]:     validate_repo_id(arg_value)
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank1]:     raise HFValidationError(
[rank1]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt'. Use `repo_type` argument if needed.

[rank1]: During handling of the above exception, another exception occurred:

[rank1]: Traceback (most recent call last):
[rank1]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank1]:   File "<frozen runpy>", line 88, in _run_code
[rank1]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/__main__.py", line 530, in <module>
[rank1]:     cli_evaluate()
[rank1]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/__main__.py", line 449, in cli_evaluate
[rank1]:     results = evaluator.simple_evaluate(
[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/utils.py", line 439, in _wrapper
[rank1]:     return fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/evaluator.py", line 226, in simple_evaluate
[rank1]:     lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
[rank1]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/api/model.py", line 151, in create_from_arg_string
[rank1]:     return cls(**args, **args2)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/models/huggingface.py", line 168, in __init__
[rank1]:     self._get_config(
[rank1]:   File "/home/gplsi/GPLSI/evaluation/lm-evaluation-harness/lm_eval/models/huggingface.py", line 527, in _get_config
[rank1]:     self._config = transformers.AutoConfig.from_pretrained(
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1153, in from_pretrained
[rank1]:     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank1]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/configuration_utils.py", line 595, in get_config_dict
[rank1]:     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank1]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/transformers/configuration_utils.py", line 677, in _get_config_dict
[rank1]:     raise OSError(
[rank1]: OSError: Can't load the configuration of '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/gplsi/NAS/GPLSI/ALIA/modelos/Continual/Maria-Silvia/hf_models/iter-225279-ckpt' is the correct path to a directory containing a config.json file
[rank0]:[W528 17:48:34.405895546 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W0528 17:48:35.145000 859019 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 859079 closing signal SIGTERM
E0528 17:48:35.259000 859019 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 859078) of binary: /home/gplsi/rst29/anaconda3/envs/hardness/bin/python3.12
Traceback (most recent call last):
  File "/home/gplsi/rst29/anaconda3/envs/hardness/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1189, in launch_command
    multi_gpu_launcher(args)
  File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/accelerate/commands/launch.py", line 815, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
  File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gplsi/rst29/anaconda3/envs/hardness/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
lm_eval FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-28_17:48:35
  host      : titan.iuii.ua.es
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 859078)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
